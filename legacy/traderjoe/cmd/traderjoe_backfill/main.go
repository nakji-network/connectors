// Code generated by connectorgen.
// go run ./connectors/source/traderjoe/cmd/traderjoe_backfill/main.go --fromBlock 11945500 --toBlock 11945502
package main

import (
	"context"
	"encoding/json"
	"math/big"
	"net/http"
	"net/url"
	"time"

	"blep.ai/data/chain/avalanche/avaxclient"
	"blep.ai/data/config"
	"blep.ai/data/connectors/source/traderjoe"
	"blep.ai/data/database"
	"github.com/nakji-network/connector/kafkautils"

	ethtypes "github.com/ava-labs/coreth/core/types"
	"github.com/ava-labs/coreth/interfaces"
	ethcommon "github.com/ethereum/go-ethereum/common"
	"github.com/rs/zerolog/log"
	"github.com/spf13/pflag"

	_ "net/http/pprof"
)

type Status struct {
	Step            int
	EventsProcessed map[string]uint64
	CurrentBlock    uint64
	Errors          []error
	FromBlock       int64
	ToBlock         int64
}

func main() {
	// Memory profiling
	go http.ListenAndServe(":6060", nil)

	// Load config in here to support flags
	pflag.Int64("fromBlock", 10000835, "backfill from this block")
	pflag.Int64("toBlock", 12000000, "backfill to this block")
	pflag.Int64("blockChunk", 3000, "get 100 blocks at a time to prevent timeouts")
	pflag.Int64P("maxConnections", "c", 10, "max simultaneous connections")
	pflag.Bool("upsert", true, "uses batch instead of COPY FROM when existing entries might exist")
	pflag.Int("dbBatch", 3000, "batch db writes by x items")
	pflag.Int64("processPairConcurrency", 4096, "max goroutines for pairProcessLog")

	var conf = config.InitConfig()

	conf.SetDefault("traderjoe.joebarAddress", "0x57319d41F71E81F3c65F2a47CA4e001EbAFd4F33")
	conf.SetDefault("traderjoe.joefactoryAddress", "0x9Ad6C38BE94206cA50bb0d90783181662f0Cfa10")
	conf.SetDefault("traderjoe.joehattokenAddress", "0x82FE038Ea4b50f9C957da326C412ebd73462077C")

	conf.SetDefault("traderjoe.joetokenAddress", "0x6e84a6216eA6dACC71eE8E6b0a5B7322EEbC0fDd")
	conf.SetDefault("traderjoe.joetrollerAddress", "0xdc13687554205E5b89Ac783db14bb5bba4A1eDaC")
	conf.SetDefault("traderjoe.masterchefjoev2Address", "0xd6a4F121CA35509aF06A0Be99093d08462f53052")
	conf.SetDefault("traderjoe.masterchefjoev3Address", "0x188bED1968b795d5c9022F6a0bb5931Ac4c18F00")

	// get status of this long running status
	status := Status{
		FromBlock: conf.GetInt64("fromBlock"),
		ToBlock:   conf.GetInt64("toBlock"),
	}
	http.HandleFunc("/status", func(w http.ResponseWriter, req *http.Request) {
		js, err := json.Marshal(status)
		if err != nil {
			http.Error(w, err.Error(), http.StatusInternalServerError)
			return
		}
		w.Header().Set("Content-Type", "application/json")
		w.Write(js)
	})
	go http.ListenAndServe(":8080", nil)

	// Load Topic registry
	kafkautils.TopicTypeRegistry.Load(traderjoe.TopicTypes)

	rpcUrls := []string{(&url.URL{
		Scheme: conf.GetString("ethereum.archival.scheme"),
		User:   url.UserPassword(conf.GetString("ethereum.archival.username"), conf.GetString("ethereum.archival.password")),
		Host:   conf.GetString("ethereum.archival.host"),
		Path:   conf.GetString("ethereum.archival.path"),
	}).String(),
		(&url.URL{ // hacky to get past wss error
			Scheme: "wss",
			User:   url.UserPassword(conf.GetString("ethereum.archival.username"), conf.GetString("ethereum.archival.password")),
			Host:   conf.GetString("ethereum.archival.host"),
			Path:   conf.GetString("ethereum.archival.path"),
		}).String()}

	ethClientPool, err := avaxclient.DialPoolContext(context.Background(), rpcUrls)
	if err != nil {
		log.Fatal().Err(err).Msg("Ethereum RPC connection error")
	}

	// Init historical db
	db, err := database.New(conf.GetString("timescaledb.connection"))
	if err != nil {
		log.Fatal().Err(err).Str("dsn", conf.GetString("timescaledb.connection")).Msg("Timescaledb connection failed")
	}
	defer db.Close()

	joebarAddress := ethcommon.HexToAddress(conf.GetString("traderjoe.joebarAddress"))
	joefactoryAddress := ethcommon.HexToAddress(conf.GetString("traderjoe.joefactoryAddress"))
	joehattokenAddress := ethcommon.HexToAddress(conf.GetString("traderjoe.joehattokenAddress"))

	joetokenAddress := ethcommon.HexToAddress(conf.GetString("traderjoe.joetokenAddress"))
	joetrollerAddress := ethcommon.HexToAddress(conf.GetString("traderjoe.joetrollerAddress"))
	masterchefjoev2Address := ethcommon.HexToAddress(conf.GetString("traderjoe.masterchefjoev2Address"))
	masterchefjoev3Address := ethcommon.HexToAddress(conf.GetString("traderjoe.masterchefjoev3Address"))

	addresses := []ethcommon.Address{
		joebarAddress,
		joefactoryAddress,
		joehattokenAddress,

		joetokenAddress,
		joetrollerAddress,
		masterchefjoev2Address,
		masterchefjoev3Address,
	}

	addresses = append(addresses, traderjoe.GetJoePairAddresses(db)...)

	query := interfaces.FilterQuery{
		Addresses: addresses,
		FromBlock: big.NewInt(conf.GetInt64("fromBlock")),
		ToBlock:   big.NewInt(conf.GetInt64("toBlock")),
	}

	client, err := ethClientPool.RandClient(true)
	if err != nil {
		log.Fatal().Err(err).Msg("failed to find available client")
	}

	logsChan, _ := client.ChunkedFilterLogs(query, 0, conf.GetInt64("blockChunk"), conf.GetInt64("maxConnections"))

	start := time.Now()

	topics := map[string]kafkautils.Topic{
		"joebar_approval":                      kafkautils.MustParseTopic(conf.GetString("traderjoe.kafka.topic.joebar_approval"), conf.GetString("kafka.env")),
		"joebar_transfer":                      kafkautils.MustParseTopic(conf.GetString("traderjoe.kafka.topic.joebar_transfer"), conf.GetString("kafka.env")),
		"joefactory_paircreated":               kafkautils.MustParseTopic(conf.GetString("traderjoe.kafka.topic.joefactory_paircreated"), conf.GetString("kafka.env")),
		"joehattoken_approval":                 kafkautils.MustParseTopic(conf.GetString("traderjoe.kafka.topic.joehattoken_approval"), conf.GetString("kafka.env")),
		"joehattoken_transfer":                 kafkautils.MustParseTopic(conf.GetString("traderjoe.kafka.topic.joehattoken_transfer"), conf.GetString("kafka.env")),
		"joepair_approval":                     kafkautils.MustParseTopic(conf.GetString("traderjoe.kafka.topic.joepair_approval"), conf.GetString("kafka.env")),
		"joepair_burn":                         kafkautils.MustParseTopic(conf.GetString("traderjoe.kafka.topic.joepair_burn"), conf.GetString("kafka.env")),
		"joepair_mint":                         kafkautils.MustParseTopic(conf.GetString("traderjoe.kafka.topic.joepair_mint"), conf.GetString("kafka.env")),
		"joepair_paircreated":                  kafkautils.MustParseTopic(conf.GetString("traderjoe.kafka.topic.joepair_paircreated"), conf.GetString("kafka.env")),
		"joepair_swap":                         kafkautils.MustParseTopic(conf.GetString("traderjoe.kafka.topic.joepair_swap"), conf.GetString("kafka.env")),
		"joepair_sync":                         kafkautils.MustParseTopic(conf.GetString("traderjoe.kafka.topic.joepair_sync"), conf.GetString("kafka.env")),
		"joepair_transfer":                     kafkautils.MustParseTopic(conf.GetString("traderjoe.kafka.topic.joepair_transfer"), conf.GetString("kafka.env")),
		"joetoken_approval":                    kafkautils.MustParseTopic(conf.GetString("traderjoe.kafka.topic.joetoken_approval"), conf.GetString("kafka.env")),
		"joetoken_delegatechanged":             kafkautils.MustParseTopic(conf.GetString("traderjoe.kafka.topic.joetoken_delegatechanged"), conf.GetString("kafka.env")),
		"joetoken_delegatevoteschanged":        kafkautils.MustParseTopic(conf.GetString("traderjoe.kafka.topic.joetoken_delegatevoteschanged"), conf.GetString("kafka.env")),
		"joetoken_ownershiptransferred":        kafkautils.MustParseTopic(conf.GetString("traderjoe.kafka.topic.joetoken_ownershiptransferred"), conf.GetString("kafka.env")),
		"joetoken_transfer":                    kafkautils.MustParseTopic(conf.GetString("traderjoe.kafka.topic.joetoken_transfer"), conf.GetString("kafka.env")),
		"joetroller_failure":                   kafkautils.MustParseTopic(conf.GetString("traderjoe.kafka.topic.joetroller_failure"), conf.GetString("kafka.env")),
		"joetroller_newadmin":                  kafkautils.MustParseTopic(conf.GetString("traderjoe.kafka.topic.joetroller_newadmin"), conf.GetString("kafka.env")),
		"joetroller_newimplementation":         kafkautils.MustParseTopic(conf.GetString("traderjoe.kafka.topic.joetroller_newimplementation"), conf.GetString("kafka.env")),
		"joetroller_newpendingadmin":           kafkautils.MustParseTopic(conf.GetString("traderjoe.kafka.topic.joetroller_newpendingadmin"), conf.GetString("kafka.env")),
		"joetroller_newpendingimplementation":  kafkautils.MustParseTopic(conf.GetString("traderjoe.kafka.topic.joetroller_newpendingimplementation"), conf.GetString("kafka.env")),
		"masterchefjoev2_add":                  kafkautils.MustParseTopic(conf.GetString("traderjoe.kafka.topic.masterchefjoev2_add"), conf.GetString("kafka.env")),
		"masterchefjoev2_deposit":              kafkautils.MustParseTopic(conf.GetString("traderjoe.kafka.topic.masterchefjoev2_deposit"), conf.GetString("kafka.env")),
		"masterchefjoev2_emergencywithdraw":    kafkautils.MustParseTopic(conf.GetString("traderjoe.kafka.topic.masterchefjoev2_emergencywithdraw"), conf.GetString("kafka.env")),
		"masterchefjoev2_harvest":              kafkautils.MustParseTopic(conf.GetString("traderjoe.kafka.topic.masterchefjoev2_harvest"), conf.GetString("kafka.env")),
		"masterchefjoev2_ownershiptransferred": kafkautils.MustParseTopic(conf.GetString("traderjoe.kafka.topic.masterchefjoev2_ownershiptransferred"), conf.GetString("kafka.env")),
		"masterchefjoev2_set":                  kafkautils.MustParseTopic(conf.GetString("traderjoe.kafka.topic.masterchefjoev2_set"), conf.GetString("kafka.env")),
		"masterchefjoev2_setdevaddress":        kafkautils.MustParseTopic(conf.GetString("traderjoe.kafka.topic.masterchefjoev2_setdevaddress"), conf.GetString("kafka.env")),
		"masterchefjoev2_updateemissionrate":   kafkautils.MustParseTopic(conf.GetString("traderjoe.kafka.topic.masterchefjoev2_updateemissionrate"), conf.GetString("kafka.env")),
		"masterchefjoev2_updatepool":           kafkautils.MustParseTopic(conf.GetString("traderjoe.kafka.topic.masterchefjoev2_updatepool"), conf.GetString("kafka.env")),
		"masterchefjoev2_withdraw":             kafkautils.MustParseTopic(conf.GetString("traderjoe.kafka.topic.masterchefjoev2_withdraw"), conf.GetString("kafka.env")),
		"masterchefjoev3_add":                  kafkautils.MustParseTopic(conf.GetString("traderjoe.kafka.topic.masterchefjoev3_add"), conf.GetString("kafka.env")),
		"masterchefjoev3_deposit":              kafkautils.MustParseTopic(conf.GetString("traderjoe.kafka.topic.masterchefjoev3_deposit"), conf.GetString("kafka.env")),
		"masterchefjoev3_emergencywithdraw":    kafkautils.MustParseTopic(conf.GetString("traderjoe.kafka.topic.masterchefjoev3_emergencywithdraw"), conf.GetString("kafka.env")),
		"masterchefjoev3_harvest":              kafkautils.MustParseTopic(conf.GetString("traderjoe.kafka.topic.masterchefjoev3_harvest"), conf.GetString("kafka.env")),
		"masterchefjoev3_init":                 kafkautils.MustParseTopic(conf.GetString("traderjoe.kafka.topic.masterchefjoev3_init"), conf.GetString("kafka.env")),
		"masterchefjoev3_ownershiptransferred": kafkautils.MustParseTopic(conf.GetString("traderjoe.kafka.topic.masterchefjoev3_ownershiptransferred"), conf.GetString("kafka.env")),
		"masterchefjoev3_set":                  kafkautils.MustParseTopic(conf.GetString("traderjoe.kafka.topic.masterchefjoev3_set"), conf.GetString("kafka.env")),
		"masterchefjoev3_updatepool":           kafkautils.MustParseTopic(conf.GetString("traderjoe.kafka.topic.masterchefjoev3_updatepool"), conf.GetString("kafka.env")),
		"masterchefjoev3_withdraw":             kafkautils.MustParseTopic(conf.GetString("traderjoe.kafka.topic.masterchefjoev3_withdraw"), conf.GetString("kafka.env")),
	}

	connector := traderjoe.Connector{
		Topics: topics,
	}

	// database write buffer
	buffer := make([]*kafkautils.Message, 0, conf.GetInt("dbBatch"))

	logToMessage := map[string]func(ethtypes.Log) *kafkautils.Message{
		conf.GetString("traderjoe.joebarAddress"):          connector.JoeBarLogToMsg,
		conf.GetString("traderjoe.joehattokenAddress"):     connector.JoeHatTokenLogToMsg,
		conf.GetString("traderjoe.joepairAddress"):         connector.JoePairLogToMsg,
		conf.GetString("traderjoe.joetokenAddress"):        connector.JoeTokenLogToMsg,
		conf.GetString("traderjoe.joetrollerAddress"):      connector.JoeTrollerLogToMsg,
		conf.GetString("traderjoe.masterchefjoev2Address"): connector.MasterChefJoeV2LogToMsg,
		conf.GetString("traderjoe.masterchefjoev3Address"): connector.MasterChefJoeV3LogToMsg,
	}

	for evLog := range logsChan {
		status.CurrentBlock = evLog.BlockNumber
		msg := logToMessage[evLog.Address.Hex()](evLog)
		status.EventsProcessed[msg.Topic.Schema()]++

		buffer = append(buffer, msg)

		// Flush to db
		if len(buffer) == conf.GetInt("dbBatch") {
			if conf.GetBool("upsert") {
				errs := db.InsertBatchKafkaMessages(buffer)
				for _, err := range errs {
					log.Error().Err(err).
						Msg("InsertBatchKafkaMessages error")
					status.Errors = append(status.Errors, err)
				}
			} else {
				err = db.CopyFromKafkaMessages(context.Background(), "liquiditypoolevent", buffer)
				if err != nil {
					log.Error().Err(err).
						Msg("CopyFromKafkaMessages error")
					status.Errors = append(status.Errors, err)
				}
			}

			log.Info().
				Dur("time", time.Since(start)).
				Interface("lastmsg", msg).
				//Interface("status", status).
				Msg("traderjoe backfill in progress")

			buffer = nil
		}
	}

	// Flush remaining buffer
	if conf.GetBool("upsert") {
		errs := db.InsertBatchKafkaMessages(buffer)
		for _, err := range errs {
			log.Error().Err(err).
				Msg("InsertBatchKafkaMessages error")
			status.Errors = append(status.Errors, err)
		}
	} else {
		err = db.CopyFromKafkaMessages(context.Background(), "liquiditypoolevent", buffer)
		if err != nil {
			log.Error().Err(err).
				Msg("CopyFromKafkaMessages error")
			status.Errors = append(status.Errors, err)
		}
	}

	log.Info().
		Dur("totaltime", time.Since(start)).
		Interface("status", &status).
		Msg("traderjoe backfill completed")
}
